{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGeneration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeYwrrglYZ0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from random import randint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "Oit0RkNVqJLK",
        "outputId": "dfce4a46-4d20-416d-ae63-ab6696e66152"
      },
      "source": [
        "file = open('Ancient_Modern_Physics.txt','r')\n",
        "text = file.read()\n",
        "file.close()\n",
        "text[:1000]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ANCIENT AND MODERN PHYSICS\\n\\nby Thomas E. Willson\\n\\n\\n\\nContents\\n\\nPreface\\nI.     Physical Basis of Metaphysics\\nII.    The Two Kinds of Perception\\nIII.   Matter and Ether\\nIV.    What a Teacher Should Teach\\nV.     The Four Manifested Planes\\nVI.    One Place on Earth\\nVII.   The Four Globes\\nVIII.  The Battle Ground\\nIX.    The Dual Man\\nX.     The Septenary World\\nXI.    Stumbling blocks in Eastern Physics\\n\\n\\n\\n\\nPREFACE\\n\\n\\nThe Editor of the Theosophical Forum in April, 1901, noted the\\ndeath of Mr. Thomas E. Willson in the previous month in an\\narticle which we reproduce for the reason that we believe many\\nreaders who have been following the chapters of \"Ancient and\\nModern Physics\" during the last year will like to know something\\nof the author.  In these paragraphs is said all that need be said\\nof one of our most devoted and understanding Theosophists.\\n\\nIn March, 1901, The Theosophical Forum lost one of its most\\nwilling and unfailing contributors.  Mr. T.E. Willson died\\nsuddenly, and the news of his d'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt_wfxXiqqCk"
      },
      "source": [
        "# Cleaning Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBAut3f6qo7O",
        "outputId": "53895a7f-324b-408e-8cc1-e95e6e44846c"
      },
      "source": [
        "tokens = text.lower()\n",
        "print(tokens[:500])\n",
        "#\n",
        "n_chars = len(tokens)\n",
        "unique_vocab = len(set(tokens))\n",
        "print('Total Tokens: %d' % n_chars)\n",
        "print('Unique Tokens: %d' % unique_vocab)\n",
        "#\n",
        "characters = sorted(list(set(tokens)))\n",
        "n_vocab = len(characters)\n",
        "print('N Vocab:',n_vocab)\n",
        "#\n",
        "int_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_int = {char:n for n, char in enumerate(characters)}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ancient and modern physics\n",
            "\n",
            "by thomas e. willson\n",
            "\n",
            "\n",
            "\n",
            "contents\n",
            "\n",
            "preface\n",
            "i.     physical basis of metaphysics\n",
            "ii.    the two kinds of perception\n",
            "iii.   matter and ether\n",
            "iv.    what a teacher should teach\n",
            "v.     the four manifested planes\n",
            "vi.    one place on earth\n",
            "vii.   the four globes\n",
            "viii.  the battle ground\n",
            "ix.    the dual man\n",
            "x.     the septenary world\n",
            "xi.    stumbling blocks in eastern physics\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "preface\n",
            "\n",
            "\n",
            "the editor of the theosophical forum in april, 1901, noted the\n",
            "death of mr. thomas e. w\n",
            "Total Tokens: 126361\n",
            "Unique Tokens: 51\n",
            "N Vocab: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K0UwQh4vhnt"
      },
      "source": [
        "# Creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0z9Lhk9vgmv"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "seq_length = 100\n",
        "\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = tokens[i:i + seq_length]\n",
        "    seq_out = tokens[i + seq_length]\n",
        "    X.append([char_to_int[char] for char in seq_in])\n",
        "    y.append(char_to_int[seq_out])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEIK_FhOvt51",
        "outputId": "0f82034a-d8ab-49c2-daa0-b0af33ea4b64"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "126361"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GexIbsLkvYvA",
        "outputId": "03664e2b-30e5-4232-978c-46cbf4e54eb4"
      },
      "source": [
        "len(X),len(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(126261, 126261)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moykMqRtvpAL",
        "outputId": "530724ba-5b1e-44cf-ca36-ec8ee897b8ce"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25, 38, 27, 33, 29, 38, 44, 1, 25, 38, 28, 1, 37, 39, 28, 29, 42, 38, 1, 40, 32, 49, 43, 33, 27, 43, 0, 0, 26, 49, 1, 44, 32, 39, 37, 25, 43, 1, 29, 8, 1, 47, 33, 36, 36, 43, 39, 38, 0, 0, 0, 0, 27, 39, 38, 44, 29, 38, 44, 43, 0, 0, 40, 42, 29, 30, 25, 27, 29, 0, 33, 8, 1, 1, 1, 1, 1, 40, 32, 49, 43, 33, 27, 25, 36, 1, 26, 25, 43, 33, 43, 1, 39, 30, 1, 37, 29, 44, 25, 40]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT_w5W0SvyGd",
        "outputId": "a09a4307-a7c2-41ac-b261-9a35c6b4fb87"
      },
      "source": [
        "print(y[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67LpSUHrv0aP"
      },
      "source": [
        "X_new = np.reshape(X, (len(X), seq_length, 1)) #samples, time steps, features\n",
        "X_new = X_new / float(n_vocab) #normalizing the values\n",
        "\n",
        "y_new = to_categorical(y) #one hot encode"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mApxvPuOv-0j",
        "outputId": "0ae02955-5fdc-4358-80e3-f13ec0ddc401"
      },
      "source": [
        "print(\"X_new shape:\", X_new.shape)\n",
        "print(\"y_new shape:\", y_new.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_new shape: (126261, 100, 1)\n",
            "y_new shape: (126261, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AlPUWsiv_2Y",
        "outputId": "9d6c0d85-d300-46ae-8f9c-0fc8b4ed3e2f"
      },
      "source": [
        "y_new[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX1hgD23wDJV"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5a_zyCFwBZD"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(350,input_shape=(X_new.shape[1],X_new.shape[2]),return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(350,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(350))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y_new.shape[1], activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIPg8HTCwsUm",
        "outputId": "818b5de4-2f25-40fa-e2d1-58bf48b8d886"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 350)          492800    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 350)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 350)          981400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 350)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 350)               981400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 51)                17901     \n",
            "=================================================================\n",
            "Total params: 2,473,501\n",
            "Trainable params: 2,473,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31kHPOUgwza_"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h2aciCXw1ky",
        "outputId": "040ab66d-58a7-4a79-95ce-05b8a33e5561"
      },
      "source": [
        "model.fit(X_new, y_new, batch_size=64, epochs=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1973/1973 [==============================] - 273s 133ms/step - loss: 3.0268\n",
            "Epoch 2/5\n",
            "1973/1973 [==============================] - 263s 134ms/step - loss: 2.9869\n",
            "Epoch 3/5\n",
            "1973/1973 [==============================] - 264s 134ms/step - loss: 2.9867\n",
            "Epoch 4/5\n",
            "1973/1973 [==============================] - 264s 134ms/step - loss: 2.9830\n",
            "Epoch 5/5\n",
            "1973/1973 [==============================] - 264s 134ms/step - loss: 2.9808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8870418710>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDSyacmbw7UM"
      },
      "source": [
        "# model.save('../data/text_generation/text_generation_model.h5')\n",
        "# model_ = load_model('../data/text_generation/text_generation_model.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BvXILwSw937"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEeDDQ9zw-di"
      },
      "source": [
        "ini = np.random.randint(0, len(X)-1)\n",
        "token_string = X[ini]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWAYHPyy9ec_",
        "outputId": "d2f06c99-32e0-4b65-f539-a09a5ae1e842"
      },
      "source": [
        "ini,X[ini]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2333,\n",
              " [29,\n",
              "  1,\n",
              "  44,\n",
              "  32,\n",
              "  29,\n",
              "  1,\n",
              "  42,\n",
              "  39,\n",
              "  39,\n",
              "  30,\n",
              "  43,\n",
              "  1,\n",
              "  39,\n",
              "  30,\n",
              "  1,\n",
              "  44,\n",
              "  32,\n",
              "  29,\n",
              "  1,\n",
              "  44,\n",
              "  25,\n",
              "  36,\n",
              "  36,\n",
              "  29,\n",
              "  43,\n",
              "  44,\n",
              "  1,\n",
              "  32,\n",
              "  39,\n",
              "  45,\n",
              "  43,\n",
              "  29,\n",
              "  43,\n",
              "  1,\n",
              "  33,\n",
              "  38,\n",
              "  1,\n",
              "  44,\n",
              "  32,\n",
              "  29,\n",
              "  0,\n",
              "  28,\n",
              "  33,\n",
              "  43,\n",
              "  44,\n",
              "  42,\n",
              "  33,\n",
              "  27,\n",
              "  44,\n",
              "  8,\n",
              "  1,\n",
              "  1,\n",
              "  44,\n",
              "  32,\n",
              "  29,\n",
              "  42,\n",
              "  29,\n",
              "  1,\n",
              "  32,\n",
              "  29,\n",
              "  1,\n",
              "  43,\n",
              "  25,\n",
              "  44,\n",
              "  1,\n",
              "  25,\n",
              "  44,\n",
              "  1,\n",
              "  32,\n",
              "  33,\n",
              "  43,\n",
              "  1,\n",
              "  28,\n",
              "  29,\n",
              "  43,\n",
              "  35,\n",
              "  6,\n",
              "  1,\n",
              "  31,\n",
              "  29,\n",
              "  38,\n",
              "  29,\n",
              "  42,\n",
              "  25,\n",
              "  36,\n",
              "  36,\n",
              "  49,\n",
              "  1,\n",
              "  33,\n",
              "  38,\n",
              "  1,\n",
              "  32,\n",
              "  33,\n",
              "  43,\n",
              "  1,\n",
              "  43,\n",
              "  32,\n",
              "  33,\n",
              "  42,\n",
              "  44])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxq6ieTgxDre",
        "outputId": "ed402b5c-bd62-4ddc-8abd-3034c79fb9a0"
      },
      "source": [
        "complete_string = [int_to_char[value] for value in token_string]\n",
        "\n",
        "print (\"\\\"\", ''.join(complete_string), \"\\\"\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" e the roofs of the tallest houses in the\n",
            "district.  there he sat at his desk, generally in his shirt \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1z_qXz8xE3k"
      },
      "source": [
        "for i in range(500):\n",
        "    x = np.reshape(token_string, (1, len(token_string), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    \n",
        "    prediction = model.predict(x, verbose=0)\n",
        "\n",
        "    id_pred = np.argmax(prediction)\n",
        "    seq_in = [int_to_char[value] for value in token_string]\n",
        "    \n",
        "    complete_string.append(int_to_char[id_pred])\n",
        "    \n",
        "    token_string.append(id_pred)\n",
        "    token_string = token_string[1:len(token_string)] "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5El_kG4WxG0n",
        "outputId": "c85e0fe6-e7e0-48b9-ccd0-3498c7789000"
      },
      "source": [
        "# Show Text\n",
        "text = \"\"\n",
        "for char in complete_string:\n",
        "    text = text + char\n",
        "print(text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e the roofs of the tallest houses in the\n",
            "district.  there he sat at his desk, generally in his shirt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhi61EY5IS3h"
      },
      "source": [
        "Ou seja, modelo não ficou muito bom..."
      ]
    }
  ]
}